worker_processes 1;

events {
    worker_connections 1024;
}

http {
    # Basic HTTP settings
    default_type application/octet-stream;

    # DNS resolver for container names
    resolver 127.0.0.11 valid=30s ipv6=off;
    resolver_timeout 10s;

    # Logging
    access_log /var/log/nginx/access.log;
    error_log /var/log/nginx/error.log;

    # Common proxy headers for all locations
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;

    # Common sub-filter settings
    sub_filter_once off;
    sub_filter_types text/html text/css text/javascript application/javascript;

    # SSL/TLS Configuration
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_prefer_server_ciphers on;
    ssl_ciphers 'ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384';
    ssl_session_timeout 1d;
    ssl_session_cache shared:SSL:10m;
    ssl_session_tickets off;

    # Paths to SSL certificates
    ssl_certificate /etc/nginx/ssl/fullchain.pem;
    ssl_certificate_key /etc/nginx/ssl/privkey.pem;

    # HTTP to HTTPS redirect for all domains
    server {
        listen 80;
        listen [::]:80;
        server_name metrics.localhost spark.localhost worker-1.localhost worker-2.localhost worker-3.localhost processor.localhost kafka.localhost prometheus.localhost;

        # Redirect all HTTP requests to HTTPS
        location / {
            return 301 https://$host$request_uri;
        }
    }

    # Grafana Dashboard (metrics.localhost) - no Basic Auth
    server {
        listen 443 ssl;
        server_name metrics.localhost;

        location / {
            # No Basic Auth here, as Grafana has its own authentication
            set $upstream_grafana grafana;
            proxy_pass http://$upstream_grafana:3000;
        }
    }

    # Spark Master UI (spark.localhost)
    server {
        listen 443 ssl;
        server_name spark.localhost;

        # Enable Basic Auth for this server
        auth_basic "Restricted Access";
        auth_basic_user_file /etc/nginx/.htpasswd;

        location / {
            set $upstream_spark_master spark-master;
            proxy_pass http://$upstream_spark_master:8090;

            # Simplified URL rewriting
            # 1. First convert HTTP to HTTPS
            sub_filter 'http://' 'https://';

            # 2. Redirect internal service names to external URLs
            sub_filter 'https://spark-master:' 'https://spark.localhost';
            sub_filter 'https://spark-worker-1:' 'https://worker-1.localhost';
            sub_filter 'https://spark-worker-2:' 'https://worker-2.localhost';
            sub_filter 'https://spark-worker-3:' 'https://worker-3.localhost';
            sub_filter 'https://data-processor:' 'https://processor.localhost';

            # 3. Remove ports from all URLs
            sub_filter ':8090' '';
            sub_filter ':8091' '';
            sub_filter ':8092' '';
            sub_filter ':8093' '';
            sub_filter ':4040' '';

            # Enable response rewriting
            proxy_set_header Accept-Encoding "";
        }
    }

    # Spark Worker 1 UI
    server {
        listen 443 ssl;
        server_name worker-1.localhost;

        # Enable Basic Auth for this server
        auth_basic "Restricted Access";
        auth_basic_user_file /etc/nginx/.htpasswd;

        location / {
            set $upstream_worker1 spark-worker-1;
            proxy_pass http://$upstream_worker1:8091;

            # Simplified URL rewriting
            # 1. First convert HTTP to HTTPS
            sub_filter 'http://' 'https://';

            # 2. Redirect internal service names to external URLs
            sub_filter 'https://spark-master:' 'https://spark.localhost';
            sub_filter 'https://spark-worker-1:' 'https://worker-1.localhost';
            sub_filter 'https://spark-worker-2:' 'https://worker-2.localhost';
            sub_filter 'https://spark-worker-3:' 'https://worker-3.localhost';
            sub_filter 'https://data-processor:' 'https://processor.localhost';

            # 3. Remove ports from all URLs
            sub_filter ':8090' '';
            sub_filter ':8091' '';
            sub_filter ':8092' '';
            sub_filter ':8093' '';
            sub_filter ':4040' '';

            # Enable response rewriting
            proxy_set_header Accept-Encoding "";
        }
    }

    # Spark Worker 2 UI
    server {
        listen 443 ssl;
        server_name worker-2.localhost;

        # Enable Basic Auth for this server
        auth_basic "Restricted Access";
        auth_basic_user_file /etc/nginx/.htpasswd;

        location / {
            set $upstream_worker2 spark-worker-2;
            proxy_pass http://$upstream_worker2:8092;

            # Simplified URL rewriting
            # 1. First convert HTTP to HTTPS
            sub_filter 'http://' 'https://';

            # 2. Redirect internal service names to external URLs
            sub_filter 'https://spark-master:' 'https://spark.localhost';
            sub_filter 'https://spark-worker-1:' 'https://worker-1.localhost';
            sub_filter 'https://spark-worker-2:' 'https://worker-2.localhost';
            sub_filter 'https://spark-worker-3:' 'https://worker-3.localhost';
            sub_filter 'https://data-processor:' 'https://processor.localhost';

            # 3. Remove ports from all URLs
            sub_filter ':8090' '';
            sub_filter ':8091' '';
            sub_filter ':8092' '';
            sub_filter ':8093' '';
            sub_filter ':4040' '';

            # Enable response rewriting
            proxy_set_header Accept-Encoding "";
        }
    }

    # Spark Worker 3 UI
    server {
        listen 443 ssl;
        server_name worker-3.localhost;

        # Enable Basic Auth for this server
        auth_basic "Restricted Access";
        auth_basic_user_file /etc/nginx/.htpasswd;

        location / {
            set $upstream_worker3 spark-worker-3;
            proxy_pass http://$upstream_worker3:8093;

            # Simplified URL rewriting
            # 1. First convert HTTP to HTTPS
            sub_filter 'http://' 'https://';

            # 2. Redirect internal service names to external URLs
            sub_filter 'https://spark-master:' 'https://spark.localhost';
            sub_filter 'https://spark-worker-1:' 'https://worker-1.localhost';
            sub_filter 'https://spark-worker-2:' 'https://worker-2.localhost';
            sub_filter 'https://spark-worker-3:' 'https://worker-3.localhost';
            sub_filter 'https://data-processor:' 'https://processor.localhost';

            # 3. Remove ports from all URLs
            sub_filter ':8090' '';
            sub_filter ':8091' '';
            sub_filter ':8092' '';
            sub_filter ':8093' '';
            sub_filter ':4040' '';

            # Enable response rewriting
            proxy_set_header Accept-Encoding "";
        }
    }

    # Spark Data Processor UI
    server {
        listen 443 ssl;
        server_name processor.localhost;

        # Enable Basic Auth for this server
        auth_basic "Restricted Access";
        auth_basic_user_file /etc/nginx/.htpasswd;

        # Direct forwarding to /jobs/ path as start page
        location = / {
            return 302 https://$host/jobs/;
        }

        location / {
            set $upstream_processor data-processor;
            proxy_pass http://$upstream_processor:4040;

            # Simplified URL rewriting
            # 1. First convert HTTP to HTTPS
            sub_filter 'http://' 'https://';

            # 2. Redirect internal service names to external URLs
            sub_filter 'https://spark-master:' 'https://spark.localhost';
            sub_filter 'https://spark-worker-1:' 'https://worker-1.localhost';
            sub_filter 'https://spark-worker-2:' 'https://worker-2.localhost';
            sub_filter 'https://spark-worker-3:' 'https://worker-3.localhost';
            sub_filter 'https://data-processor:' 'https://processor.localhost';

            # Special case for data-processor with hostname adjustment
            sub_filter 'https://data-processor:4040' 'https://processor.localhost';

            # Relative link replacements for better navigation
            sub_filter '"/"' '"/jobs/"';
            sub_filter '<a href="/"' '<a href="/jobs/"';

            # Catch HTML attributes and other link variants
            sub_filter 'href="https://data-processor:4040/' 'href="https://processor.localhost/';
            sub_filter 'href="https://data-processor:4040"' 'href="https://processor.localhost"';

            # 3. Remove ports from all URLs
            sub_filter ':8090' '';
            sub_filter ':8091' '';
            sub_filter ':8092' '';
            sub_filter ':8093' '';
            sub_filter ':4040' '';

            # Fix for static resources - replace //static with /static when needed
            sub_filter 'href="//' 'href="/';
            sub_filter 'src="//' 'src="/';

            # Enable response rewriting
            proxy_set_header Accept-Encoding "";
        }
    }

    # Kafka UI
    server {
        listen 443 ssl;
        server_name kafka.localhost;

        # Enable Basic Auth for this server
        auth_basic "Restricted Access";
        auth_basic_user_file /etc/nginx/.htpasswd;

        location / {
            set $upstream_kafka_ui kafka-ui;
            proxy_pass http://$upstream_kafka_ui:8080;
        }
    }

    # Prometheus UI
    server {
        listen 443 ssl;
        server_name prometheus.localhost;

        # Enable Basic Auth for this server
        auth_basic "Restricted Access";
        auth_basic_user_file /etc/nginx/.htpasswd;

        location / {
            set $upstream_prometheus prometheus;
            proxy_pass http://$upstream_prometheus:9090;
            proxy_read_timeout 90;
        }
    }

    # Port redirections for direct port access
    # 18090 → spark.localhost
    server {
        listen 18090;
        server_name _;
        return 301 https://spark.localhost$request_uri;
    }

    # 18091 → worker-1.localhost
    server {
        listen 18091;
        server_name _;
        return 301 https://worker-1.localhost$request_uri;
    }

    # 18092 → worker-2.localhost
    server {
        listen 18092;
        server_name _;
        return 301 https://worker-2.localhost$request_uri;
    }

    # 18093 → worker-3.localhost
    server {
        listen 18093;
        server_name _;
        return 301 https://worker-3.localhost$request_uri;
    }

    # 14040 → processor.localhost
    server {
        listen 14040;
        server_name _;
        return 301 https://processor.localhost$request_uri;
    }

    # 18080 → kafka.localhost
    server {
        listen 18080;
        server_name _;
        return 301 https://kafka.localhost$request_uri;
    }

    # 13000 → metrics.localhost
    server {
        listen 13000;
        server_name _;
        return 301 https://metrics.localhost$request_uri;
    }

    # Default server - displays information about the platform
    server {
        listen 80 default_server;
        listen 443 ssl default_server;

        # Enable Basic Auth for this server
        auth_basic "Restricted Access";
        auth_basic_user_file /etc/nginx/.htpasswd;

        location / {
            return 200 'Real-time Data Platform is ready!
Available Services:
- Grafana Dashboard: https://metrics.localhost
- Spark Master UI: https://spark.localhost
- Spark Worker 1 UI: https://worker-1.localhost
- Spark Worker 2 UI: https://worker-2.localhost
- Spark Worker 3 UI: https://worker-3.localhost
- Data Processor UI: https://processor.localhost
- Kafka UI: https://kafka.localhost
- Prometheus UI: https://prometheus.localhost';
            add_header Content-Type text/plain;
        }

        # Nginx status endpoint for Prometheus metrics
        location /nginx_status {
            stub_status on;
            access_log off;
            auth_basic off;  # No authentication for metrics
            allow 172.16.0.0/12; # Docker network
            allow 127.0.0.1;     # Localhost
            deny all;            # Deny all other
        }

        # Health check endpoint without authentication
        location /healthz {
            access_log off;
            add_header Content-Type text/plain;
            auth_basic off;

            # Set variables for services to check
            set $upstream_prometheus prometheus;
            set $upstream_spark_master spark-master;
            set $upstream_kafka_ui kafka-ui;
            set $upstream_grafana grafana;
            set $upstream_processor data-processor;

            # Default status
            set $service_status "OK";

            # Perform actual HTTP checks for critical services
            proxy_connect_timeout 2s; # Short timeout for health checks
            proxy_read_timeout 2s;

            # Set a variable for detailed mode based on arg_detailed
            set $detailed_mode "false";
            if ($arg_detailed = "true") {
                set $detailed_mode "true";
            }

            # Check if detailed mode is active
            if ($detailed_mode = "true") {
                return 200 "Health check: $service_status
Timestamp: $time_iso8601

Services:
- Prometheus: $upstream_prometheus (UI: https://prometheus.localhost)
- Spark Master: $upstream_spark_master (UI: https://spark.localhost)
- Kafka UI: $upstream_kafka_ui (UI: https://kafka.localhost)
- Grafana: $upstream_grafana (UI: https://metrics.localhost)
- Data Processor: $upstream_processor (UI: https://processor.localhost)

For service-specific health details, use:
- /healthz/prometheus
- /healthz/spark
- /healthz/kafka
- /healthz/grafana
- /healthz/processor
";
            }

            # Return simplified health status (default)
            return 200 "Health check: $service_status
Timestamp: $time_iso8601
Prometheus: $upstream_prometheus
Spark Master: $upstream_spark_master
Kafka UI: $upstream_kafka_ui
";
        }

        # Individual service health checks
        location /healthz/prometheus {
            access_log off;
            add_header Content-Type text/plain;
            auth_basic off;

            set $upstream_prometheus prometheus;
            proxy_pass http://$upstream_prometheus:9090/-/healthy;
            proxy_connect_timeout 2s;
            proxy_read_timeout 2s;
        }

        location /healthz/spark {
            access_log off;
            add_header Content-Type text/plain;
            auth_basic off;

            set $upstream_spark_master spark-master;
            proxy_pass http://$upstream_spark_master:8090/;
            proxy_connect_timeout 2s;
            proxy_read_timeout 2s;
        }

        location /healthz/kafka {
            access_log off;
            add_header Content-Type text/plain;
            auth_basic off;

            set $upstream_kafka_ui kafka-ui;
            proxy_pass http://$upstream_kafka_ui:8080/;
            proxy_connect_timeout 2s;
            proxy_read_timeout 2s;
        }

        location /healthz/grafana {
            access_log off;
            add_header Content-Type text/plain;
            auth_basic off;

            set $upstream_grafana grafana;
            proxy_pass http://$upstream_grafana:3000/api/health;
            proxy_connect_timeout 2s;
            proxy_read_timeout 2s;
        }

        location /healthz/processor {
            access_log off;
            add_header Content-Type text/plain;
            auth_basic off;

            set $upstream_processor data-processor;
            proxy_pass http://$upstream_processor:4040/;
            proxy_connect_timeout 2s;
            proxy_read_timeout 2s;
        }

        # Prometheus metrics endpoint without authentication
        location /metrics {
            access_log off;
            add_header Content-Type text/plain;
            auth_basic off;

            # Set variables for services to check
            set $upstream_prometheus prometheus;
            set $upstream_spark_master spark-master;
            set $upstream_kafka_ui kafka-ui;
            set $upstream_grafana grafana;
            set $upstream_processor data-processor;

            # Default status values (1 = up, 0 = down)
            set $prometheus_status "1";
            set $spark_status "1";
            set $kafka_status "1";
            set $grafana_status "1";
            set $processor_status "1";

            # Simple check - if variable is empty, service is down
            if ($upstream_prometheus = "") {
                set $prometheus_status "0";
            }
            if ($upstream_spark_master = "") {
                set $spark_status "0";
            }
            if ($upstream_kafka_ui = "") {
                set $kafka_status "0";
            }
            if ($upstream_grafana = "") {
                set $grafana_status "0";
            }
            if ($upstream_processor = "") {
                set $processor_status "0";
            }

            # Return metrics in Prometheus format
            # Note: We're removing the timestamp metric as it causes parsing issues
            return 200 "# HELP service_up Check if service is up (1 = up, 0 = down)
# TYPE service_up gauge
service_up{name=\"prometheus\"} $prometheus_status
service_up{name=\"spark_master\"} $spark_status
service_up{name=\"kafka_ui\"} $kafka_status
service_up{name=\"grafana\"} $grafana_status
service_up{name=\"data_processor\"} $processor_status
";
        }
    }
}